name: Deploy to Linode

"on":
  push:
    branches: [main]
  workflow_dispatch: # Allow manual trigger

env:
  REGISTRY: ghcr.io
  IMAGE_NAME_API: evaou/ai-scraper-api
  IMAGE_NAME_WORKER: evaou/ai-scraper-worker

jobs:
  test:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_PASSWORD: password
          POSTGRES_USER: postgres
          POSTGRES_DB: test_scraper
          PGDATA: /var/lib/postgresql/data/pgdata
        options: >-
          --health-cmd "pg_isready -U postgres"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"
          cache-dependency-path: "requirements*.txt"

      - name: Cache pip dependencies
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt', '**/pyproject.toml') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y postgresql-client redis-tools

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -e ".[test]"
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: |
          playwright install --with-deps chromium

      - name: Wait for services to be ready
        run: |
          # Wait for PostgreSQL
          echo "Waiting for PostgreSQL to be ready..."
          postgres_ready=false
          for i in {1..30}; do
            if pg_isready -h localhost -p 5432 -U postgres > /dev/null 2>&1; then
              echo "âœ… PostgreSQL is ready"
              postgres_ready=true
              break
            fi
            echo "â³ Waiting for PostgreSQL... ($i/30)"
            sleep 2
          done

          if [ "$postgres_ready" != "true" ]; then
            echo "âŒ PostgreSQL failed to become ready after 60 seconds"
            exit 1
          fi

          # Wait for Redis
          echo "Waiting for Redis to be ready..."
          redis_ready=false
          for i in {1..30}; do
            if redis-cli -h localhost -p 6379 ping > /dev/null 2>&1; then
              echo "âœ… Redis is ready"
              redis_ready=true
              break
            fi
            echo "â³ Waiting for Redis... ($i/30)"
            sleep 2
          done

          if [ "$redis_ready" != "true" ]; then
            echo "âŒ Redis failed to become ready after 60 seconds"
            exit 1
          fi

          echo "ğŸ‰ All services are ready!"

      - name: Run tests
        env:
          DATABASE_URL: postgresql+asyncpg://postgres:password@localhost:5432/test_scraper
          REDIS_URL: redis://localhost:6379/0
          PYTHONPATH: .
        run: |
          pytest tests/ -v --tb=short --maxfail=5

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Pre-build Docker cleanup (free space)
        run: |
          echo "ğŸ§¹ Disk space before cleanup:" && df -h
          echo "Docker images before cleanup:" && docker image ls -a | head -n 20 || true
          echo "Pruning..."
          docker system prune -af || true
          docker volume prune -f || true
          # Remove dangling build cache if any (Buildx often handles, but just in case)
          docker builder prune -af || true
          echo "ğŸ§¹ Disk space after cleanup:" && df -h

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Container Registry
        uses: docker/login-action@v3
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Extract metadata for API
        id: meta-api
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_API }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push API image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.api
          push: true
          tags: ${{ steps.meta-api.outputs.tags }}
          labels: ${{ steps.meta-api.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: false
          sbom: false

      - name: Verify API build context completeness
        run: |
          for path in requirements.txt alembic.ini migrations app; do
            if [ ! -e "$path" ]; then
              echo "âŒ Missing expected build context item: $path" >&2
              exit 1
            else
              echo "âœ… Found $path"
            fi
          done

      - name: Show built API tags
        run: |
          echo "ğŸ·ï¸ API Tags built and pushed:"
          echo "${{ steps.meta-api.outputs.tags }}"

      - name: Extract metadata for Worker
        id: meta-worker
        uses: docker/metadata-action@v5
        with:
          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME_WORKER }}
          tags: |
            type=ref,event=branch
            type=ref,event=pr
            type=sha,prefix={{branch}}-
            type=raw,value=latest,enable={{is_default_branch}}

      - name: Build and push Worker image
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./docker/Dockerfile.worker
          push: true
          tags: ${{ steps.meta-worker.outputs.tags }}
          labels: ${{ steps.meta-worker.outputs.labels }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
          provenance: false
          sbom: false

      - name: Verify Worker build context completeness
        run: |
          for path in requirements.txt alembic.ini migrations app; do
            if [ ! -e "$path" ]; then
              echo "âŒ Missing expected build context item: $path" >&2
              exit 1
            else
              echo "âœ… Found $path"
            fi
          done

      - name: Show built Worker tags
        run: |
          echo "ğŸ·ï¸ Worker Tags built and pushed:"
          echo "${{ steps.meta-worker.outputs.tags }}"

  deploy:
    needs: build-and-push
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    environment: production

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check deployment secrets
        id: check-secrets
        run: |
          echo "ğŸ” Checking deployment secrets..."

          # List what we're checking (without revealing values)
          echo "Required secrets:"
          echo "  - LINODE_HOST: ${{ secrets.LINODE_HOST != '' && 'âœ… SET' || 'âŒ NOT SET' }}"
          echo "  - LINODE_USER: ${{ secrets.LINODE_USER != '' && 'âœ… SET' || 'âŒ NOT SET' }}"
          echo "  - SSH_PRIVATE_KEY: ${{ secrets.SSH_PRIVATE_KEY != '' && 'âœ… SET' || 'âŒ NOT SET' }}"
          echo "  - POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD != '' && 'âœ… SET' || 'âŒ NOT SET' }}"
          echo "  - REDIS_PASSWORD: ${{ secrets.REDIS_PASSWORD != '' && 'âœ… SET' || 'âŒ NOT SET' }}"
          echo "  - JWT_SECRET_KEY: ${{ secrets.JWT_SECRET_KEY != '' && 'âœ… SET' || 'âŒ NOT SET' }}"

          if [[ -z "${{ secrets.LINODE_HOST }}" || -z "${{ secrets.LINODE_USER }}" || -z "${{ secrets.SSH_PRIVATE_KEY }}" ]]; then
            echo "deployment-ready=false" >> $GITHUB_OUTPUT
            echo "âŒ Critical deployment secrets not configured - skipping deployment"
            echo ""
            echo "To fix: Add missing secrets in GitHub repository Settings > Secrets and variables > Actions"
          else
            echo "deployment-ready=true" >> $GITHUB_OUTPUT
            echo "âœ… Deployment secrets configured - proceeding with deployment"
          fi

      - name: Create deployment files
        if: steps.check-secrets.outputs.deployment-ready == 'true'
        run: |
          # Create short SHA for image tags
          SHORT_SHA=$(echo "${{ github.sha }}" | cut -c1-7)

          # Create environment file for production
          {
            echo "# Database Configuration"
            echo "POSTGRES_DB=${{ secrets.POSTGRES_DB }}"
            echo "POSTGRES_USER=${{ secrets.POSTGRES_USER }}"
            echo "POSTGRES_PASSWORD=${{ secrets.POSTGRES_PASSWORD }}"
            echo "DATABASE_URL=postgresql+asyncpg://${{ secrets.POSTGRES_USER }}:${{ secrets.POSTGRES_PASSWORD }}@db:5432/${{ secrets.POSTGRES_DB }}"
            echo ""
            echo "# Redis Configuration - using individual components for better reliability"
            echo "REDIS_PASSWORD=${{ secrets.REDIS_PASSWORD }}"
            echo "REDIS_HOST=redis"
            echo "REDIS_PORT=6379"
            echo "REDIS_DB=0"
            echo "REDIS_URL=redis://redis:6379/0"
            echo ""
            echo "# API Configuration"
            echo "JWT_SECRET_KEY=${{ secrets.JWT_SECRET_KEY }}"
            echo "API_KEY_REQUIRED=true"
            echo "ENABLE_DOCS=true"  # Expose docs in production
            echo ""
            echo "# Image tags (use short SHA to match docker metadata action)"
            echo "API_IMAGE_TAG=${{ env.REGISTRY }}/${{ env.IMAGE_NAME_API }}:${{ github.ref_name }}-${SHORT_SHA}"
            echo "WORKER_IMAGE_TAG=${{ env.REGISTRY }}/${{ env.IMAGE_NAME_WORKER }}:${{ github.ref_name }}-${SHORT_SHA}"
          } > .env.prod

      - name: Copy files to server
        if: steps.check-secrets.outputs.deployment-ready == 'true'
        uses: appleboy/scp-action@v0.1.7
        with:
          host: ${{ secrets.LINODE_HOST }}
          username: ${{ secrets.LINODE_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          port: 22
          source: "docker-compose.prod.yml,.env.prod,docker/,scripts/"
          target: "/opt/ai-scraper/"
          strip_components: 0

      - name: Deploy to server
        if: steps.check-secrets.outputs.deployment-ready == 'true'
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.LINODE_HOST }}
          username: ${{ secrets.LINODE_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          port: 22
          script: |
            set -e
            cd /opt/ai-scraper

            echo "ğŸ§¹ Remote pre-deploy cleanup (free old images)"
            docker system prune -af || true
            docker volume prune -f || true
            df -h

            # Log in to GitHub Container Registry (suppress credential warning)
            echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin 2>/dev/null || echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u "${{ github.actor }}" --password-stdin

            # Load environment variables
            export $(cat .env.prod | grep -v '^#' | grep -v '^\s*$' | sed 's/#.*//' | xargs)

            # Create necessary directories
            mkdir -p ./secrets ./logs ./data/postgres ./data/redis

            # Debug: Show what image tags we're trying to use
            echo "ğŸ³ Deploying with images:"
            echo "  API: ${API_IMAGE_TAG}"
            echo "  Worker: ${WORKER_IMAGE_TAG}"

            # Update docker-compose.prod.yml with new image tags
            sed -i "s|image: ghcr.io/evaou/ai-scraper-api:.*|image: ${API_IMAGE_TAG}|g" docker-compose.prod.yml
            sed -i "s|image: ghcr.io/evaou/ai-scraper-worker:.*|image: ${WORKER_IMAGE_TAG}|g" docker-compose.prod.yml

            # Debug: Show what was actually updated
            echo "ğŸ” Updated docker-compose.prod.yml images:"
            grep "image: ghcr.io/evaou/ai-scraper-" docker-compose.prod.yml

            # Pull new images with fallback to latest if specific tag fails
            echo "ğŸ“¥ Attempting to pull images..."
            if ! docker compose -f docker-compose.prod.yml pull; then
              echo "âš ï¸  Failed to pull images with specific tags, checking what's available..."

              # Check what tags exist for debugging
              echo "ğŸ” Available tags for API:"
              docker manifest ls ${API_IMAGE_TAG} 2>/dev/null || echo "Tag not found: ${API_IMAGE_TAG}"

              echo "ğŸ” Trying to fallback to latest tags..."
              # Fallback to latest tags
              API_IMAGE_LATEST=${{ env.REGISTRY }}/${{ env.IMAGE_NAME_API }}:latest
              WORKER_IMAGE_LATEST=${{ env.REGISTRY }}/${{ env.IMAGE_NAME_WORKER }}:latest
              sed -i "s|image: ghcr.io/evaou/ai-scraper-api:.*|image: ${API_IMAGE_LATEST}|g" docker-compose.prod.yml
              sed -i "s|image: ghcr.io/evaou/ai-scraper-worker:.*|image: ${WORKER_IMAGE_LATEST}|g" docker-compose.prod.yml

              echo "ğŸ” Updated to latest tags:"
              grep "image: ghcr.io/evaou/ai-scraper-" docker-compose.prod.yml

              if ! docker compose -f docker-compose.prod.yml pull; then
                echo "âš ï¸  Latest tags also not found. This might be the first deployment."
                echo "ğŸ› ï¸  Checking if we can build images locally..."

                # Try to build images locally as last resort
                if [ -f "docker/Dockerfile.api" ] && [ -f "docker/Dockerfile.worker" ]; then
                  echo "ğŸ“¦ Building API image locally..."
                  docker build -f docker/Dockerfile.api -t ghcr.io/evaou/ai-scraper-api:latest .

                  echo "ğŸ“¦ Building Worker image locally..."
                  docker build -f docker/Dockerfile.worker -t ghcr.io/evaou/ai-scraper-worker:latest .

                  echo "âœ… Images built locally successfully"
                else
                  echo "âš ï¸  Cannot build locally - Dockerfiles not found. Continuing anyway."
                fi
              fi
            fi

            echo "ğŸ§¹ Post-pull cleanup to ensure space"
            docker image prune -f || true
            df -h

            # Deploy with zero-downtime if script exists, otherwise simple deployment
            if [ -f "./scripts/deploy.sh" ]; then
              chmod +x ./scripts/deploy.sh
              ./scripts/deploy.sh
            else
              echo "Performing simple deployment..."
              docker compose -f docker-compose.prod.yml down
              docker compose -f docker-compose.prod.yml up -d
            fi

            # Health check and database readiness
            echo "â³ Waiting for services to be healthy..."
            sleep 30

            # Wait for database to be fully ready
            echo "ğŸ” Verifying database connectivity..."
            for i in {1..10}; do
              if docker compose -f docker-compose.prod.yml exec -T api python3 -c "import asyncio; import sys; from app.core.database import get_engine; async def check_db(): engine = get_engine(); async with engine.begin() as conn: await conn.execute('SELECT 1'); return True; result = asyncio.run(check_db()); sys.exit(0 if result else 1)"; then
                echo "âœ… Database is ready"
                break
              else
                echo "â³ Waiting for database... (attempt $i/10)"
                sleep 10
              fi

              if [ $i -eq 10 ]; then
                echo "âŒ Database failed to become ready after 100 seconds"
                exit 1
              fi
            done

            # Ensure database schema is up to date
            echo "ğŸ”„ Running database migrations..."
            docker compose -f docker-compose.prod.yml exec -T api alembic upgrade head

            # Register JWT_SECRET_KEY as API key in database with retries
            echo "ğŸ”‘ Registering JWT_SECRET_KEY as API key in database..."
            echo "ğŸ” JWT_SECRET_KEY status: ${{ secrets.JWT_SECRET_KEY != '' && 'âœ… Available' || 'âŒ Missing' }}"

            JWT_REGISTRATION_SUCCESS=false
            for attempt in {1..3}; do
              echo "ğŸ”„ JWT registration attempt $attempt/3..."

              if docker compose -f docker-compose.prod.yml exec -T api bash -c "
                export JWT_SECRET_KEY='${{ secrets.JWT_SECRET_KEY }}'
                python3 scripts/create-jwt-api-key.py
              "; then
                echo "âœ… JWT_SECRET_KEY successfully registered as API key"
                JWT_REGISTRATION_SUCCESS=true
                break
              else
                echo "âš ï¸ JWT registration attempt $attempt failed"
                if [ $attempt -lt 3 ]; then
                  echo "   Retrying in 10 seconds..."
                  sleep 10
                fi
              fi
            done

            # Fallback: Direct database registration if script fails
            if [ "$JWT_REGISTRATION_SUCCESS" = false ]; then
              echo "ğŸ”§ Attempting direct database registration..."
              if docker compose -f docker-compose.prod.yml exec -T db psql -U scraper_user -d scraper_prod -c "
                INSERT INTO api_keys (id, name, key_hash, is_active, created_at, updated_at)
                VALUES (
                  gen_random_uuid(),
                  'JWT_SECRET_KEY',
                  encode(sha256('${{ secrets.JWT_SECRET_KEY }}'::bytea), 'hex'),
                  true,
                  now(),
                  now()
                ) ON CONFLICT (key_hash) DO UPDATE SET
                  is_active = true,
                  updated_at = now();
              "; then
                echo "âœ… JWT_SECRET_KEY registered via direct database insertion"
                JWT_REGISTRATION_SUCCESS=true
              else
                echo "âŒ All JWT registration methods failed"
              fi
            fi

            # Comprehensive API and JWT testing
            echo "ğŸ§ª Testing API endpoints and JWT authentication..."

            # Basic health check first
            if curl -f http://localhost/api/v1/health/live || curl -f http://localhost:8000/api/v1/health/live; then
              echo "âœ… Basic health check passed"
            else
              echo "âŒ Basic health check failed"
              exit 1
            fi

            # Test JWT API key authentication with detailed feedback
            echo "ğŸ”‘ Testing JWT_SECRET_KEY authentication..."
            API_TEST_RESPONSE=$(curl -s -w "\nHTTP_STATUS:%{http_code}\nTIME_TOTAL:%{time_total}" \
              -X POST http://localhost/api/v1/scrape \
              -H "Content-Type: application/json" \
              -H "X-API-Key: ${{ secrets.JWT_SECRET_KEY }}" \
              -d '{"url": "https://httpbin.org/html", "options": {"extract_text": true, "timeout": 15}}' \
              2>/dev/null || echo -e "\nHTTP_STATUS:000\nTIME_TOTAL:0")

            HTTP_CODE=$(echo "$API_TEST_RESPONSE" | grep "HTTP_STATUS:" | cut -d: -f2)
            RESPONSE_TIME=$(echo "$API_TEST_RESPONSE" | grep "TIME_TOTAL:" | cut -d: -f2)
            RESPONSE_BODY=$(echo "$API_TEST_RESPONSE" | sed '/HTTP_STATUS:/d' | sed '/TIME_TOTAL:/d')

            echo "ğŸ“Š API Test Results:"
            echo "   HTTP Status: $HTTP_CODE"
            echo "   Response Time: ${RESPONSE_TIME}s"
            echo "   Response: $RESPONSE_BODY"

            if [ "$HTTP_CODE" = "202" ]; then
              echo "âœ… JWT_SECRET_KEY API authentication SUCCESSFUL!"
              echo "ğŸš€ Enhanced API mode is active and ready for workflows"

              # Extract job ID for follow-up testing
              JOB_ID=$(echo "$RESPONSE_BODY" | grep -o '"job_id":"[^"]*"' | cut -d'"' -f4)
              if [ -n "$JOB_ID" ]; then
                echo "ğŸ“‹ Job submitted with ID: $JOB_ID"

                # Quick job status check
                sleep 5
                JOB_STATUS=$(curl -s -H "X-API-Key: ${{ secrets.JWT_SECRET_KEY }}" \
                  "http://localhost/api/v1/jobs/$JOB_ID" | grep -o '"status":"[^"]*"' | cut -d'"' -f4 || echo "unknown")
                echo "ğŸ“Š Job status after 5s: $JOB_STATUS"
              fi

            elif [ "$HTTP_CODE" = "401" ]; then
              echo "âŒ JWT_SECRET_KEY authentication FAILED - Invalid API key"
              echo "ğŸ”§ Registration status: $JWT_REGISTRATION_SUCCESS"
              if [ "$JWT_REGISTRATION_SUCCESS" = true ]; then
                echo "   Registration succeeded but key still invalid - possible database sync issue"
              else
                echo "   Registration failed - key was never added to database"
              fi
              echo "   Manual fix: ssh root@${{ secrets.LINODE_HOST }} 'cd /opt/ai-scraper && ./scripts/fix-jwt-api-key.sh'"

            elif [ "$HTTP_CODE" = "000" ]; then
              echo "âŒ API connection failed - service may not be running"
              echo "ğŸ” Container status:"
              docker compose -f docker-compose.prod.yml ps

            else
              echo "âš ï¸ Unexpected API response (HTTP: $HTTP_CODE)"
              echo "   Response body: $RESPONSE_BODY"
            fi


            # Final deployment validation
            echo ""
            echo "ğŸ Deployment Validation Summary"
            echo "================================"

            # Container health summary
            echo "ğŸ“¦ Container Status:"
            docker compose -f docker-compose.prod.yml ps --format "table {{.Name}}\t{{.Status}}\t{{.Ports}}"

            # API endpoint summary
            echo ""
            echo "ğŸŒ API Endpoints:"
            echo "   Health: http://${{ secrets.LINODE_HOST }}/api/v1/health"
            echo "   Docs: http://${{ secrets.LINODE_HOST }}/docs"
            echo "   Scrape: http://${{ secrets.LINODE_HOST }}/api/v1/scrape"

            # Authentication summary
            echo ""
            echo "ğŸ”‘ Authentication Status:"
            if [ "$JWT_REGISTRATION_SUCCESS" = true ] && [ "$HTTP_CODE" = "202" ]; then
              echo "   âœ… JWT_SECRET_KEY is registered and working"
              echo "   âœ… API authentication fully functional"
            elif [ "$JWT_REGISTRATION_SUCCESS" = true ] && [ "$HTTP_CODE" != "202" ]; then
              echo "   âš ï¸ JWT_SECRET_KEY registered but authentication failed"
              echo "   ğŸ”§ May need manual verification"
            else
              echo "   âŒ JWT_SECRET_KEY registration failed"
              echo "   ğŸ”§ Manual fix required: ./scripts/fix-jwt-api-key.sh"
            fi

            # Workflow integration summary
            echo ""
            echo "ğŸ”„ Workflow Integration:"
            echo "   USD Rate: GitHub Actions â†’ API (JWT auth)"
            echo "   Stock Price: GitHub Actions â†’ API (JWT auth)"
            echo "   Bruno Tests: Available in bruno-collection/"

            # Manual troubleshooting info
            if [ "$JWT_REGISTRATION_SUCCESS" != true ] || [ "$HTTP_CODE" != "202" ]; then
              echo ""
              echo "ğŸ› ï¸ Manual Troubleshooting:"
              echo "   1. SSH: ssh root@${{ secrets.LINODE_HOST }}"
              echo "   2. Navigate: cd /opt/ai-scraper"
              echo "   3. Fix JWT: ./scripts/fix-jwt-api-key.sh"
              echo "   4. Test: curl -H 'X-API-Key: ${{ secrets.JWT_SECRET_KEY }}' http://localhost/api/v1/health"
            fi

            echo ""
            if [ "$HTTP_CODE" = "202" ]; then
              echo "ğŸ‰ DEPLOYMENT SUCCESSFUL - All systems operational!"
            else
              echo "âš ï¸ DEPLOYMENT COMPLETED - Manual JWT fix may be needed"
            fi

            # Clean up old images
            docker image prune -f
              exit 1
            fi

      - name: Deployment skipped message
        if: steps.check-secrets.outputs.deployment-ready == 'false'
        run: |
          echo "â­ï¸ Deployment skipped - server secrets not configured"
          echo ""
          echo "To enable deployment, configure the following secrets in GitHub:"
          echo "  â€¢ LINODE_HOST - Your deployment server IP/hostname"
          echo "  â€¢ LINODE_USER - SSH username for your server"
          echo "  â€¢ SSH_PRIVATE_KEY - SSH private key content"
          echo "  â€¢ POSTGRES_DB, POSTGRES_USER, POSTGRES_PASSWORD - Database credentials"
          echo "  â€¢ REDIS_PASSWORD - Redis password"
          echo "  â€¢ JWT_SECRET_KEY - JWT signing secret"
          echo ""
          echo "âœ… Build and push completed successfully!"

  rollback:
    needs: [deploy]
    runs-on: ubuntu-latest
    if: failure() && github.ref == 'refs/heads/main'
    steps:
      - name: Check rollback secrets
        id: check-rollback-secrets
        run: |
          if [[ -z "${{ secrets.LINODE_HOST }}" || -z "${{ secrets.LINODE_USER }}" || -z "${{ secrets.SSH_PRIVATE_KEY }}" ]]; then
            echo "rollback-ready=false" >> $GITHUB_OUTPUT
            echo "âš ï¸ Rollback secrets not configured - skipping rollback"
          else
            echo "rollback-ready=true" >> $GITHUB_OUTPUT
            echo "âœ… Rollback secrets configured - proceeding with rollback"
          fi

      - name: Rollback on deployment failure
        if: steps.check-rollback-secrets.outputs.rollback-ready == 'true'
        uses: appleboy/ssh-action@v1.0.3
        with:
          host: ${{ secrets.LINODE_HOST }}
          username: ${{ secrets.LINODE_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          port: 22
          script: |
            set -e
            cd /opt/ai-scraper

            echo "ğŸ”„ Attempting rollback..."

            # Restore previous configuration if backup exists
            if [ -f ".env.prod.backup" ]; then
              cp .env.prod.backup .env.prod
              echo "âœ… Configuration restored"

              # Deploy previous version
              docker compose -f docker-compose.prod.yml up -d

              # Wait for health check
              sleep 30
              if curl -f http://localhost/api/v1/health/live; then
                echo "âœ… Rollback successful"
              else
                echo "âŒ Rollback failed"
                exit 1
              fi
            else
              echo "âš ï¸ No backup found for rollback"
            fi

  notify:
    needs: [deploy, rollback]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Notify deployment status
        run: |
          if [ "${{ needs.deploy.result }}" == "success" ]; then
            echo "âœ… Deployment to Linode successful!"
            echo ""
            echo "ğŸŒ HTTP API available at: http://paramita-scraper.duckdns.org/api/v1"
            echo "ğŸ“š API Documentation: http://paramita-scraper.duckdns.org/api/v1/docs"
            echo ""
            echo "ğŸ”‘ JWT API Authentication:"
            echo "  âœ… JWT_SECRET_KEY automatically registered during deployment"
            echo "  âœ… Enhanced API mode enabled for USD rate and stock price workflows"
            echo "  ğŸš€ Faster processing now active!"
            echo ""
            echo "ï¿½ğŸ”’ To enable HTTPS:"
            echo "  1. SSH to your server: ssh root@paramita-scraper.duckdns.org"
            echo "  2. Run SSL setup: cd /opt/ai-scraper && sudo ./setup-ssl-enhanced.sh"
            echo "  3. Update GitHub workflows to use HTTPS URLs"
          elif [ "${{ needs.rollback.result }}" == "success" ]; then
            echo "ğŸ”„ Deployment failed but rollback successful"
          elif [ "${{ needs.deploy.result }}" == "skipped" ]; then
            echo "â­ï¸ Build successful, deployment skipped (secrets not configured)"
          else
            echo "âŒ Workflow completed with issues"
          fi
